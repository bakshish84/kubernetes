Important Note: All pods running in kube-system namespace means control pods have hostnetwork: true  means they are not assigned Pod network. so IPS assigned to Pods will be host network IP.

CNI stands for Container Network Interface. As the name suggests, CNI works on the networking level where CNI takes care of the pods and other things in Kubernetes. CNI
ensures how the containers and pods should connect to the network. There are many CNIs available in the market but today we will discuss Calico CNI.

Calico is an open source network and network security designed for kubernetes. Calico works only on networking to provide fine-grained control overs the containers, pods, nodes or multiple clusters.

Alternatives of Calico:

1. Flannel
2. Weave
3. Cilium
4. Kube-router


Advantages of Calico:

● Advanced Networking Policies : With Calico CNI, we can define fine-grained networking policies over the containers or pods such as which pod can communicate
to which other pod and apply rules based on labels, ports, and more. This level of control is not possible through Kubernetes Native Networking.
● Scalability : Calico is known for its Scalability where it can handle large clusters with ease and efficiently manage network traffic which makes it suitable for
enterprise-level applications with multiple pods.
● Cross-Cluster Networking : Calico can be used to connect multiple Kubernetes clusters together, which can be beneficial in hybrid or multi-cluster scenarios.
● Border Gateway Protocol(BGP) routing : Calico supports BGP for routing which is quite good if you want to integrate with on-premises data centers or public cloud
environments.
● Security : Calico supports a very good level of security over the network traffic where Calico encrypts the network traffic so only authorized pods can communicate with
the respective pods.


Key Concepts and Real-time Example
● IP Address Management : Calico supports managing the IP address for each pod where each pod is assigned to a unique IP address from the cluster’s IP address
range.
● Routing and Network Policy : Calico enables routing for the network traffic between pods. The Network policies can be applied to control traffic between pods. So, you
can allow or deny communications between specific pods.
● Load Balancing : Calico handles load balancing in which it distributes the traffic between multiple pods.
● Security and Encryption : Calico provides security features to protect your Kubernetes clusters. It encrypts the network traffic so that you can ensure only
authorized pods can communicate.



Core features:

1. Layer 3 based routing (BGP or IP-in-IP/VXLAN for encapsulation)
2. Network policies
3. Integration with kubernetes, Opnestack and bare metal workloads.
4. Suppprt eBPF dataplane (alternative to iptables)


Key concepts:

1. Calico Data Planes:
Calico supports multiple data planes

- Linux iptables: Default in many setups; uses iptables rules for network policy enforcement
- eBPF: High performance, modern kernel-level data plane with better observability and performance.


2. Encapsulation Modes:
- No encapsulation (BGP Mode): works well in environments using native L3 routing.
- IP-in-IP: useful when you dont have native routing between nodes.
- VXLAN: for environments like Public Clouds where IP-in-IP may be restricted.
- WireGuard: for encrypted Pod-to-Pod communication.


Architecture Components:

1. Calico Node (Daemon Set)

- Runs on every node
- Handles route programming and network policy enforcement
- Contains components like Felix and BIRD

2. Felix

- The calico agent reposnible for programming routes and iptables rules
- Enforce policies and manages workload endpoints.

3. Typha

- Optimizes scalability by aggregating updates between the kuberenetes API server and many calico-node agents

4. BIRD

- BGP daemon used for route advertisement in native routing mode.



Check which encapsulation mode is used:

# calicoctl get ippools --allow-version-mismatch -o yaml 
apiVersion: projectcalico.org/v3
items:
- apiVersion: projectcalico.org/v3
  kind: IPPool
  metadata:
    creationTimestamp: "2025-01-23T18:48:03Z"
    name: default-ipv4-ippool
    resourceVersion: "590"
    uid: ae2a2016-ff06-4e83-b7b6-3913c0c7a3bf
  spec:
    allowedUses:
    - Workload
    - Tunnel
    blockSize: 26
    cidr: 10.96.0.0/16
    ipipMode: Always
    natOutgoing: true
    nodeSelector: all()
    vxlanMode: Never
kind: IPPoolList
metadata:
  resourceVersion: "428072"
#


[root@control Deployment]# calicoctl get ippools --allow-version-mismatch -o wide
NAME                  CIDR           NAT    IPIPMODE   VXLANMODE   DISABLED   DISABLEBGPEXPORT   SELECTOR   
default-ipv4-ippool   10.96.0.0/16   true   Always     Never       false      false              all()      

[root@control Deployment]#


Change routing from ip-in-ip to VXLAN

# calicoctl get ippool default-ipv4-ippool --allow-version-mismatch -o yaml > ippool.yaml
# vi ippool.yaml  # change ipinip to Never and VXLAN to Always
# calicoctl apply -f ippool.yaml
Version mismatch.
Client Version:   v3.27.0
Cluster Version:  3.28.2
Use --allow-version-mismatch to override.

# calicoctl apply -f ippool.yaml --allow-version-mismatch
Successfully applied 1 'IPPool' resource(s)
# kubectl rollout restart daemonset calico-node -n kube-system
daemonset.apps/calico-node restarted

# calicoctl get ippool default-ipv4-ippool --allow-version-mismatch -o wide
NAME                  CIDR           NAT    IPIPMODE   VXLANMODE   DISABLED   DISABLEBGPEXPORT   SELECTOR   
default-ipv4-ippool   10.96.0.0/16   true   Never      Always      false      false              all()      

[root@control Deployment]# 


Get IP pool details assigned by calico
# calicoctl ipam show --allow-version-mismatch

check if Calico recognizes the worker node

# calicoctl get nodes

